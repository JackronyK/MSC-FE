{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wbdl2MJGZifz"
   },
   "source": [
    "## STOCHASTIC MODELING\n",
    "MODULE 1 | LESSON 4\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-Lyb-5iZnu6"
   },
   "source": [
    "# **FOURIER METHODS FOR HESTON MODEL** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gAQWf79oZun1"
   },
   "source": [
    "\n",
    "|  |  |\n",
    "|:---|:---|\n",
    "|**Reading Time** |  120 minutes |\n",
    "|**Prior Knowledge** | Heston, Fourier transform, Characteristic function  |\n",
    "|**Keywords** | Heston model, Lewis, Calibration |\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bXtf2x6Swdlb"
   },
   "source": [
    "*In the first lesson of the module, we saw the performance of Fourier-based methods and Lewis's approach for option pricing under the Black-Scholes model. In this lesson, we will revisit these methods in the context of the Heston (1993) model. First, we will focus on pricing via the Heston model under these methods. Then, we will use them to calibrate the model to observed market prices.*<span style='color: transparent; font-size:1%'>All rights reserved WQU WorldQuant University QQQQ</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SUEVIHX0qIbs"
   },
   "source": [
    "## **1. Fourier-Based Pricing for Heston (1993) Model**\n",
    "\n",
    "First, we are going to see how the Fourier-based approaches perform for Heston (1993) with some pre-defined model parameters. This will require that we define several things, most importantly Heston's characteristic function. \n",
    "\n",
    "\n",
    "To start with, let's import the necessary libraries for now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 254,
     "status": "ok",
     "timestamp": 1664388805329,
     "user": {
      "displayName": "Ivan Blanco",
      "userId": "11863287364861133555"
     },
     "user_tz": -120
    },
    "id": "c5RAXHRBy-Di"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.integrate import quad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ET51Zg-ITAAu"
   },
   "source": [
    "As in the previous notebook from Lesson 1, we will go over the process for a standard European call option. Then, you can adapt the code for other options. We will specifically go over the process for following the Lewis (2001) approach. Hopefully, after this pricing process, you will be able to implement FFT by yourselves.\n",
    "\n",
    "Now, there are a few things we need before going over the pure pricing process. Let's go over these while defining an appropriate function to be used later on.\n",
    "\n",
    "### **1.1. Heston (1993) Characteristic Function**\n",
    "\n",
    "Probably the most important ingredient for Fourier transform methods such as Lewis (2001) is knowledge of the characteristic function for the underlying process. Deriving the characteristic function of Heston (1993) is not as easy and straightforward as in the case of Black-Scholes. We will present here the closed-form expression; you can check the original Heston (1993) paper or Gatheral (2006) to see the derivation of this characteristic function.\n",
    "\n",
    "The characteristic function of the Heston (1993) model is given by:\n",
    "\n",
    "$$\n",
    "\\\n",
    "\\begin{equation*}\n",
    "  \\varphi^{H} (u, T) = e^{H_1(u, T)+H_2(u,T)\\nu_0}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\\\n",
    "where\n",
    "\n",
    "$$\n",
    "\\\n",
    "\\begin{equation*}\n",
    "  H_1 (u, T) \\equiv r_0 uiT + \\frac{c_1}{\\sigma_\\nu^2}\\Biggl\\{ (\\kappa_\\nu - \\rho \\sigma_\\nu ui+c_2) T - 2 log \\left[ \\frac{1-c_3e^{c_2T}}{1-c_3} \\right] \\Biggl\\}\n",
    "\\end{equation*}\n",
    "$$\n",
    "$$\n",
    "\\\n",
    "\\begin{equation*}\n",
    "  H_2 (u, T) \\equiv \\frac{\\kappa_\\nu - \\rho \\sigma_\\nu ui + c_2}{\\sigma_\\nu^2} \\left[ \\frac{1-e^{c_2T}}{1-c_3e^{c_2T}} \\right]\n",
    "\\end{equation*}\n",
    "$$\n",
    "$$\n",
    "\\\n",
    "\\begin{equation*}\n",
    "  c_1 \\equiv \\kappa_\\nu \\theta_\\nu\n",
    "\\end{equation*}\n",
    "$$\n",
    "$$\n",
    "\\\n",
    "\\begin{equation*}\n",
    "  c_2 \\equiv - \\sqrt{(\\rho \\sigma_\\nu ui - \\kappa_\\nu)^2 - \\sigma_\\nu^2(-ui-u^2) }\n",
    "\\end{equation*}\n",
    "$$\n",
    "$$\n",
    "\\\n",
    "\\begin{equation*}\n",
    "  c_3 \\equiv \\frac{\\kappa_\\nu - \\rho \\sigma_\\nu ui + c_2}{\\kappa_\\nu - \\rho \\sigma_\\nu ui - c_2}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "\\\n",
    "As you can see, the derivation and closed-form expression for the characteristic function of the Heston model is not simple at all. Luckily for us, we can create a function in Python that simplifies its calculations every time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1664388805564,
     "user": {
      "displayName": "Ivan Blanco",
      "userId": "11863287364861133555"
     },
     "user_tz": -120
    },
    "id": "xX42TlhpIqhn"
   },
   "outputs": [],
   "source": [
    "def H93_char_func(u, T, r, kappa_v, theta_v, sigma_v, rho, v0):\n",
    "    \"\"\"Valuation of European call option in H93 model via Lewis (2001)\n",
    "    Fourier-based approach: characteristic function.\n",
    "    Parameter definitions see function BCC_call_value.\"\"\"\n",
    "    c1 = kappa_v * theta_v\n",
    "    c2 = -np.sqrt(\n",
    "        (rho * sigma_v * u * 1j - kappa_v) ** 2 - sigma_v**2 * (-u * 1j - u**2)\n",
    "    )\n",
    "    c3 = (kappa_v - rho * sigma_v * u * 1j + c2) / (\n",
    "        kappa_v - rho * sigma_v * u * 1j - c2\n",
    "    )\n",
    "    H1 = r * u * 1j * T + (c1 / sigma_v**2) * (\n",
    "        (kappa_v - rho * sigma_v * u * 1j + c2) * T\n",
    "        - 2 * np.log((1 - c3 * np.exp(c2 * T)) / (1 - c3))\n",
    "    )\n",
    "    H2 = (\n",
    "        (kappa_v - rho * sigma_v * u * 1j + c2)\n",
    "        / sigma_v**2\n",
    "        * ((1 - np.exp(c2 * T)) / (1 - c3 * np.exp(c2 * T)))\n",
    "    )\n",
    "    char_func_value = np.exp(H1 + H2 * v0)\n",
    "    return char_func_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u6Khk3I6OslU"
   },
   "source": [
    "Now that we have our characteristic function, let's move on to another important step in the pricing process.\n",
    "\n",
    "### **1.2 Integral Value in Lewis (2001)**\n",
    "\n",
    "We also need to get a value for the integral in Lewis (2001):\n",
    "\n",
    "$$\n",
    "\\\n",
    "\\begin{equation*}\n",
    "    C_0 = S_0 - \\frac{\\sqrt{S_0 K} e^{-rT}}{\\pi} \\int_{0}^{\\infty} \\mathbf{Re}[e^{izk} \\varphi(z-i/2)] \\frac{dz}{z^2+1/4}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\\\n",
    "Obviously, the expression for the integral is the same one we used for Black-Scholes, but note that the expression for the characteristic function has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1664388805910,
     "user": {
      "displayName": "Ivan Blanco",
      "userId": "11863287364861133555"
     },
     "user_tz": -120
    },
    "id": "sI-4KAveIrdM"
   },
   "outputs": [],
   "source": [
    "def H93_int_func(u, S0, K, T, r, kappa_v, theta_v, sigma_v, rho, v0):\n",
    "    \"\"\"\n",
    "    Fourier-based approach for Lewis (2001): Integration function.\n",
    "    \"\"\"\n",
    "    char_func_value = H93_char_func(\n",
    "        u - 1j * 0.5, T, r, kappa_v, theta_v, sigma_v, rho, v0\n",
    "    )\n",
    "    int_func_value = (\n",
    "        1 / (u**2 + 0.25) * (np.exp(1j * u * np.log(S0 / K)) * char_func_value).real\n",
    "    )\n",
    "    return int_func_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "riur6_D_SpGl"
   },
   "source": [
    "### **1.3 Calculating the Value of the Integral and Call Value**\n",
    "\n",
    "Finally, we will need to numerically compute the value of the aforementioned integral. As before, we will use the quadrature method (*quad*) included in the scipy package (https://docs.scipy.org/doc/scipy/reference/generated/scipy.integrate.quad.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1664388805910,
     "user": {
      "displayName": "Ivan Blanco",
      "userId": "11863287364861133555"
     },
     "user_tz": -120
    },
    "id": "I0NpF7utIraw"
   },
   "outputs": [],
   "source": [
    "def H93_call_value(S0, K, T, r, kappa_v, theta_v, sigma_v, rho, v0):\n",
    "    \"\"\"Valuation of European call option in H93 model via Lewis (2001)\n",
    "\n",
    "    Parameter definition:\n",
    "    ==========\n",
    "    S0: float\n",
    "        initial stock/index level\n",
    "    K: float\n",
    "        strike price\n",
    "    T: float\n",
    "        time-to-maturity (for t=0)\n",
    "    r: float\n",
    "        constant risk-free short rate\n",
    "    kappa_v: float\n",
    "        mean-reversion factor\n",
    "    theta_v: float\n",
    "        long-run mean of variance\n",
    "    sigma_v: float\n",
    "        volatility of variance\n",
    "    rho: float\n",
    "        correlation between variance and stock/index level\n",
    "    v0: float\n",
    "        initial level of variance\n",
    "    Returns\n",
    "    =======\n",
    "    call_value: float\n",
    "        present value of European call option\n",
    "    \"\"\"\n",
    "    int_value = quad(\n",
    "        lambda u: H93_int_func(u, S0, K, T, r, kappa_v, theta_v, sigma_v, rho, v0),\n",
    "        0,\n",
    "        np.inf,\n",
    "        limit=250,\n",
    "    )[0]\n",
    "    call_value = max(0, S0 - np.exp(-r * T) * np.sqrt(S0 * K) / np.pi * int_value)\n",
    "    return call_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6L3zk3IRUe0o"
   },
   "source": [
    "## **2. Pricing with Heston (1993) via Lewis (2001)**\n",
    "\n",
    "\\\n",
    "Now that we have all the necessary functions, let's price! \n",
    "\n",
    "\\\n",
    "We will do so for a standard European call option with the following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1664388805911,
     "user": {
      "displayName": "Ivan Blanco",
      "userId": "11863287364861133555"
     },
     "user_tz": -120
    },
    "id": "CjKeBFdNIrYn"
   },
   "outputs": [],
   "source": [
    "# Option Parameters\n",
    "S0 = 100.0\n",
    "K = 100.0\n",
    "T = 1.0\n",
    "r = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4MuYhlqZVgNd"
   },
   "source": [
    "Also, for the purpose of checking whether everything works, we will assume the following parameters for the Heston model. Remember that to obtain these parameters we will have to calibrate the model to market prices. We will do that by the end of this module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1664388805911,
     "user": {
      "displayName": "Ivan Blanco",
      "userId": "11863287364861133555"
     },
     "user_tz": -120
    },
    "id": "Gq6DDmUsIrV-"
   },
   "outputs": [],
   "source": [
    "# Heston(1993) Parameters\n",
    "kappa_v = 1.5\n",
    "theta_v = 0.02\n",
    "sigma_v = 0.15\n",
    "rho = 0.1\n",
    "v0 = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jJQRZA7WIro"
   },
   "source": [
    "Now, if we implement the whole pricing process described above, we can get to a Call option price with the mentioned characteristics and model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 454,
     "status": "ok",
     "timestamp": 1664388806360,
     "user": {
      "displayName": "Ivan Blanco",
      "userId": "11863287364861133555"
     },
     "user_tz": -120
    },
    "id": "Ya1tq5t6IrTj",
    "outputId": "d4d43692-80f2-41bf-fb1b-cc2ed156d4a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heston (1993) Call Option Value:   $    5.7578 \n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Heston (1993) Call Option Value:   $%10.4f \"\n",
    "    % H93_call_value(S0, K, T, r, kappa_v, theta_v, sigma_v, rho, v0)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oTmHCn4UXmHw"
   },
   "source": [
    "So far, you have learned how to perform pricing with the Heston (1993) stochastic volatility model under the approach by Lewis (2001). One important advantage of Fourier-based methods is that they require very little information (basically, the characteristic function of the process followed by the underlying) to arrive at a semi-analytical solution for the price of the option. \n",
    "\n",
    "As usual, most problems related with these methods arise in the market calibration process, the most important tool we have to extract the values for the different model parameters. Now, we will go over the full calibration process of the Heston model with real market data.\n",
    "\n",
    "\n",
    "## **3. Heston Model Calibration**\n",
    "\n",
    "At this point, we are going to guide you through the full process of model calibration for the Heston model. We will do this calibration by looking at market option prices. Hence, the first thing we need is options' market data to work with. \n",
    "\n",
    "Unlike in other occasions, where we directly downloaded data from Yahoo finance, due to the higher complexity in the process involved here, we will work with data in a local file. Specifically, we are going to calibrate our Heston model using market data for options on the EuroStoxx 50 index (Europe's 50 largest firms). We will take the data for just one day, September 30th, 2014. \n",
    "\n",
    "Let's start by importing some additional libraries needed:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1664388806360,
     "user": {
      "displayName": "Ivan Blanco",
      "userId": "11863287364861133555"
     },
     "user_tz": -120
    },
    "id": "lTtoCbdgtgKB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.optimize import brute, fmin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CPwkeO6tmPa"
   },
   "source": [
    "### **3.1. Gather Options' Market Data**\n",
    "\n",
    "Now, in order to load the mentioned option market data, you need to load the file provided and place it in the same directory we are working on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pytables (from versions: none)\n",
      "ERROR: No matching distribution found for pytables\n"
     ]
    }
   ],
   "source": [
    "!pip install pytables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tables in c:\\users\\user\\anaconda3\\envs\\msc_fe\\lib\\site-packages (3.10.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\user\\anaconda3\\envs\\msc_fe\\lib\\site-packages (from tables) (2.2.0)\n",
      "Requirement already satisfied: numexpr>=2.6.2 in c:\\users\\user\\anaconda3\\envs\\msc_fe\\lib\\site-packages (from tables) (2.11.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\anaconda3\\envs\\msc_fe\\lib\\site-packages (from tables) (24.1)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\user\\anaconda3\\envs\\msc_fe\\lib\\site-packages (from tables) (9.0.0)\n",
      "Requirement already satisfied: blosc2>=2.3.0 in c:\\users\\user\\anaconda3\\envs\\msc_fe\\lib\\site-packages (from tables) (3.5.1)\n",
      "Requirement already satisfied: typing-extensions>=4.4.0 in c:\\users\\user\\anaconda3\\envs\\msc_fe\\lib\\site-packages (from tables) (4.11.0)\n",
      "Requirement already satisfied: ndindex in c:\\users\\user\\anaconda3\\envs\\msc_fe\\lib\\site-packages (from blosc2>=2.3.0->tables) (1.10.0)\n",
      "Requirement already satisfied: msgpack in c:\\users\\user\\anaconda3\\envs\\msc_fe\\lib\\site-packages (from blosc2>=2.3.0->tables) (1.1.1)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\user\\anaconda3\\envs\\msc_fe\\lib\\site-packages (from blosc2>=2.3.0->tables) (3.10.0)\n",
      "Requirement already satisfied: requests in c:\\users\\user\\anaconda3\\envs\\msc_fe\\lib\\site-packages (from blosc2>=2.3.0->tables) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\envs\\msc_fe\\lib\\site-packages (from requests->blosc2>=2.3.0->tables) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\envs\\msc_fe\\lib\\site-packages (from requests->blosc2>=2.3.0->tables) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\envs\\msc_fe\\lib\\site-packages (from requests->blosc2>=2.3.0->tables) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\envs\\msc_fe\\lib\\site-packages (from requests->blosc2>=2.3.0->tables) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1664388806361,
     "user": {
      "displayName": "Ivan Blanco",
      "userId": "11863287364861133555"
     },
     "user_tz": -120
    },
    "id": "ln3dvKqltgHX"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "``C:\\Users\\USER\\OneDrive\\CB\\Msc FE\\Course Content\\5 Stochastic Modelling\\M1 Option Pricing Using Fourier Methods\\lesson 4\\option_dataset_wqu.h5`` does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Market Data from www.eurexchange.com\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# as of September 30, 2014\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m h5 \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mHDFStore(\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption_dataset_wqu.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m )  \u001b[38;5;66;03m# Place this file in the same directory before running the code\u001b[39;00m\n\u001b[0;32m      7\u001b[0m data \u001b[38;5;241m=\u001b[39m h5[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# European call & put option data (3 maturities)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m h5\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\msc_FE\\Lib\\site-packages\\pandas\\io\\pytables.py:585\u001b[0m, in \u001b[0;36mHDFStore.__init__\u001b[1;34m(self, path, mode, complevel, complib, fletcher32, **kwargs)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fletcher32 \u001b[38;5;241m=\u001b[39m fletcher32\n\u001b[0;32m    584\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 585\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopen(mode\u001b[38;5;241m=\u001b[39mmode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\msc_FE\\Lib\\site-packages\\pandas\\io\\pytables.py:745\u001b[0m, in \u001b[0;36mHDFStore.open\u001b[1;34m(self, mode, **kwargs)\u001b[0m\n\u001b[0;32m    739\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    740\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot open HDF5 file, which is already opened, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    741\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meven in read-only mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    742\u001b[0m     )\n\u001b[0;32m    743\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m--> 745\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle \u001b[38;5;241m=\u001b[39m tables\u001b[38;5;241m.\u001b[39mopen_file(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\msc_FE\\Lib\\site-packages\\tables\\file.py:325\u001b[0m, in \u001b[0;36mopen_file\u001b[1;34m(filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    320\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is already opened.  Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclose it before reopening in write mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m filename\n\u001b[0;32m    322\u001b[0m             )\n\u001b[0;32m    324\u001b[0m \u001b[38;5;66;03m# Finally, create the File instance, and return it\u001b[39;00m\n\u001b[1;32m--> 325\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m File(filename, mode, title, root_uep, filters, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\msc_FE\\Lib\\site-packages\\tables\\file.py:811\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, filename, mode, title, root_uep, filters, **kwargs)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams \u001b[38;5;241m=\u001b[39m params\n\u001b[0;32m    810\u001b[0m \u001b[38;5;66;03m# Now, it is time to initialize the File extension\u001b[39;00m\n\u001b[1;32m--> 811\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_g_new(filename, mode, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    813\u001b[0m \u001b[38;5;66;03m# Check filters and set PyTables format version for new files.\u001b[39;00m\n\u001b[0;32m    814\u001b[0m new \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v_new\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\msc_FE\\Lib\\site-packages\\tables\\hdf5extension.pyx:499\u001b[0m, in \u001b[0;36mtables.hdf5extension.File._g_new\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\USER\\anaconda3\\envs\\msc_FE\\Lib\\site-packages\\tables\\utils.py:172\u001b[0m, in \u001b[0;36mcheck_file_access\u001b[1;34m(filename, mode)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    170\u001b[0m     \u001b[38;5;66;03m# The file should be readable.\u001b[39;00m\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39maccess(path, os\u001b[38;5;241m.\u001b[39mF_OK):\n\u001b[1;32m--> 172\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`` does not exist\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39mis_file():\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIsADirectoryError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`` is not a regular file\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: ``C:\\Users\\USER\\OneDrive\\CB\\Msc FE\\Course Content\\5 Stochastic Modelling\\M1 Option Pricing Using Fourier Methods\\lesson 4\\option_dataset_wqu.h5`` does not exist"
     ]
    }
   ],
   "source": [
    "# Market Data from www.eurexchange.com\n",
    "# as of September 30, 2014\n",
    "\n",
    "h5 = pd.HDFStore(\n",
    "    \"option_dataset_wqu.h5\", \"r\"\n",
    ")  # Place this file in the same directory before running the code\n",
    "data = h5[\"data\"]  # European call & put option data (3 maturities)\n",
    "h5.close()\n",
    "S0 = 3225.93  # EURO STOXX 50 level September 30, 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h5' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m h5\n",
      "\u001b[1;31mNameError\u001b[0m: name 'h5' is not defined"
     ]
    }
   ],
   "source": [
    "h5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZKzj9srOxOkW"
   },
   "source": [
    "Once you have the market data loaded, we are going to select the options that we want to be part of the calibration process. We will select near ATM options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1664388806362,
     "user": {
      "displayName": "Ivan Blanco",
      "userId": "11863287364861133555"
     },
     "user_tz": -120
    },
    "id": "YQraLB3KtgEu",
    "outputId": "71d28dd9-261f-4169-bc85-687ce6858a97"
   },
   "outputs": [],
   "source": [
    "# Option Selection\n",
    "\n",
    "tol = 0.02  # Tolerance level to select ATM options (percent around ITM/OTM options)\n",
    "options = data[(np.abs(data[\"Strike\"] - S0) / S0) < tol]\n",
    "options[\"Date\"] = pd.DatetimeIndex(options[\"Date\"])\n",
    "options[\"Maturity\"] = pd.DatetimeIndex(options[\"Maturity\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y0Z3GneOxt8e"
   },
   "source": [
    "Then, we add time left until maturity and a constant risk-free rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1664388806362,
     "user": {
      "displayName": "Ivan Blanco",
      "userId": "11863287364861133555"
     },
     "user_tz": -120
    },
    "id": "uFggSBLktgCS",
    "outputId": "a8c29a9a-e3be-4018-a988-2fdfc927e1bf"
   },
   "outputs": [],
   "source": [
    "# Adding Time-to-Maturity and constant short-rates\n",
    "\n",
    "for row, option in options.iterrows():\n",
    "    T = (option[\"Maturity\"] - option[\"Date\"]).days / 365.0\n",
    "    options.loc[row, \"T\"] = T\n",
    "    options.loc[row, \"r\"] = 0.02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZyIs150x_IB"
   },
   "source": [
    "Let's see how the data looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1664388806363,
     "user": {
      "displayName": "Ivan Blanco",
      "userId": "11863287364861133555"
     },
     "user_tz": -120
    },
    "id": "O6-_aclKtf_5",
    "outputId": "8c828e61-f89e-425e-890c-d4b76cf8c326"
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLdUu-tw0NeV"
   },
   "source": [
    "## **3.2. Calibration Process**\n",
    "\n",
    "Now that we have the data, let's begin our calibration process. Apart from the previously defined functions (or, better said, building on those), we will need to define some additional functions to optimize our model parameters so that they match observed market data.\n",
    "\n",
    "First, we will introduce a function that will evaluate the error the model makes with respect to observed data given certain parameters. As usual, we will rely on a **mean squared error (MSE) function**. We will also define some initial values for the calibration parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1664388806363,
     "user": {
      "displayName": "Ivan Blanco",
      "userId": "11863287364861133555"
     },
     "user_tz": -120
    },
    "id": "SIbFNpL_1H9D"
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "min_MSE = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1664388806363,
     "user": {
      "displayName": "Ivan Blanco",
      "userId": "11863287364861133555"
     },
     "user_tz": -120
    },
    "id": "RAGDlmq9tf9j"
   },
   "outputs": [],
   "source": [
    "def H93_error_function(p0):\n",
    "    \"\"\"Error function for parameter calibration via\n",
    "    Lewis (2001) Fourier approach for Heston (1993).\n",
    "    Parameters\n",
    "    ==========\n",
    "    kappa_v: float\n",
    "        mean-reversion factor\n",
    "    theta_v: float\n",
    "        long-run mean of variance\n",
    "    sigma_v: float\n",
    "        volatility of variance\n",
    "    rho: float\n",
    "        correlation between variance and stock/index level\n",
    "    v0: float\n",
    "        initial, instantaneous variance\n",
    "    Returns\n",
    "    =======\n",
    "    MSE: float\n",
    "        mean squared error\n",
    "    \"\"\"\n",
    "    global i, min_MSE\n",
    "    kappa_v, theta_v, sigma_v, rho, v0 = p0\n",
    "    if kappa_v < 0.0 or theta_v < 0.005 or sigma_v < 0.0 or rho < -1.0 or rho > 1.0:\n",
    "        return 500.0\n",
    "    if 2 * kappa_v * theta_v < sigma_v**2:\n",
    "        return 500.0\n",
    "    se = []\n",
    "    for row, option in options.iterrows():\n",
    "        model_value = H93_call_value(\n",
    "            S0,\n",
    "            option[\"Strike\"],\n",
    "            option[\"T\"],\n",
    "            option[\"r\"],\n",
    "            kappa_v,\n",
    "            theta_v,\n",
    "            sigma_v,\n",
    "            rho,\n",
    "            v0,\n",
    "        )\n",
    "        se.append((model_value - option[\"Call\"]) ** 2)\n",
    "    MSE = sum(se) / len(se)\n",
    "    min_MSE = min(min_MSE, MSE)\n",
    "    if i % 25 == 0:\n",
    "        print(\"%4d |\" % i, np.array(p0), \"| %7.3f | %7.3f\" % (MSE, min_MSE))\n",
    "    i += 1\n",
    "    return MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bnvfeICX1VbG"
   },
   "source": [
    "Next, we will need a function that performs the **optimization process**. In other words, it optimizes the model parameters so as to minimize the error function with respect to market data. We will do this in 2 steps in order to look for faster convergence of the prices to market quotes. First, we will use the `brute` function of scipy (https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.brute.html), that allows the calibration to focus on most sensible ranges. Once these are declared, we can dig deeper into the specific regions and get the actual parameters more accurately with the `fmin` function (https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.fmin.html). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1664388806364,
     "user": {
      "displayName": "Ivan Blanco",
      "userId": "11863287364861133555"
     },
     "user_tz": -120
    },
    "id": "Bo54_53jtf6w"
   },
   "outputs": [],
   "source": [
    "def H93_calibration_full():\n",
    "    \"\"\"Calibrates Heston (1993) stochastic volatility model to market quotes.\"\"\"\n",
    "    # First run with brute force\n",
    "    # (scan sensible regions, for faster convergence)\n",
    "    p0 = brute(\n",
    "        H93_error_function,\n",
    "        (\n",
    "            (2.5, 10.6, 5.0),  # kappa_v\n",
    "            (0.01, 0.041, 0.01),  # theta_v\n",
    "            (0.05, 0.251, 0.1),  # sigma_v\n",
    "            (-0.75, 0.01, 0.25),  # rho\n",
    "            (0.01, 0.031, 0.01),\n",
    "        ),  # v0\n",
    "        finish=None,\n",
    "    )\n",
    "\n",
    "    # Second run with local, convex minimization\n",
    "    # (we dig deeper where promising results)\n",
    "    opt = fmin(\n",
    "        H93_error_function, p0, xtol=0.000001, ftol=0.000001, maxiter=750, maxfun=900\n",
    "    )\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLsg-ysr2y78"
   },
   "source": [
    "### 3.3. Results from Calibration\n",
    "\n",
    "Now that we have all the necessary ingredients, let's see how our calibration algorithm performs. For that, given the way we structured things before, we just need to call our *H93_calibration_full()* function. This will give us each of the different outputs from calibration, including the values given to the different parameters in the model. Before running, please be aware of the time this algorithm will take!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 171909,
     "status": "ok",
     "timestamp": 1664388978263,
     "user": {
      "displayName": "Ivan Blanco",
      "userId": "11863287364861133555"
     },
     "user_tz": -120
    },
    "id": "8Ysjib-DYg_d",
    "outputId": "b4a4e320-d2dc-49a4-c77f-54962a7de37f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'H93_error_function' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m H93_calibration_full()\n",
      "Cell \u001b[1;32mIn[26], line 6\u001b[0m, in \u001b[0;36mH93_calibration_full\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Calibrates Heston (1993) stochastic volatility model to market quotes.\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# First run with brute force\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# (scan sensible regions, for faster convergence)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m p0 \u001b[38;5;241m=\u001b[39m brute(\n\u001b[1;32m----> 6\u001b[0m     H93_error_function,\n\u001b[0;32m      7\u001b[0m     (\n\u001b[0;32m      8\u001b[0m         (\u001b[38;5;241m2.5\u001b[39m, \u001b[38;5;241m10.6\u001b[39m, \u001b[38;5;241m5.0\u001b[39m),  \u001b[38;5;66;03m# kappa_v\u001b[39;00m\n\u001b[0;32m      9\u001b[0m         (\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.041\u001b[39m, \u001b[38;5;241m0.01\u001b[39m),  \u001b[38;5;66;03m# theta_v\u001b[39;00m\n\u001b[0;32m     10\u001b[0m         (\u001b[38;5;241m0.05\u001b[39m, \u001b[38;5;241m0.251\u001b[39m, \u001b[38;5;241m0.1\u001b[39m),  \u001b[38;5;66;03m# sigma_v\u001b[39;00m\n\u001b[0;32m     11\u001b[0m         (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.75\u001b[39m, \u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.25\u001b[39m),  \u001b[38;5;66;03m# rho\u001b[39;00m\n\u001b[0;32m     12\u001b[0m         (\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.031\u001b[39m, \u001b[38;5;241m0.01\u001b[39m),\n\u001b[0;32m     13\u001b[0m     ),  \u001b[38;5;66;03m# v0\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     finish\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Second run with local, convex minimization\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# (we dig deeper where promising results)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m opt \u001b[38;5;241m=\u001b[39m fmin(\n\u001b[0;32m     20\u001b[0m     H93_error_function, p0, xtol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.000001\u001b[39m, ftol\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.000001\u001b[39m, maxiter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m750\u001b[39m, maxfun\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m900\u001b[39m\n\u001b[0;32m     21\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'H93_error_function' is not defined"
     ]
    }
   ],
   "source": [
    "H93_calibration_full()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VyEvn5_LZ6gC"
   },
   "source": [
    "Now we have finally calibrated our parameters to market values.\n",
    "\n",
    "The results from this calibration give us the following values for the parameters in the Heston (1993) model:\n",
    "\n",
    "$\\kappa_\\nu = 5.047$ \n",
    "\n",
    "$\\theta_\\nu = 0.018$ \n",
    "\n",
    "$\\sigma_\\nu = 0.434$\n",
    "\n",
    "$\\rho = -0.447$\n",
    "\n",
    "$\\nu_0 = 0.027$\n",
    "\n",
    "The next step will be simply using these parameters to price the option we want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hKANTnmYyOLr"
   },
   "source": [
    "##Â **4. Conclusion**\n",
    "\n",
    "In this lesson, we have, first, used Fourier methods to price options using the Lewis (2001) approach for the Heston (1993) model, and second, developed a full calibration of the Heston (1993) model. If you understood the full process covered in this notebook, you are on the right track to face the next module, where we will introduce a model that combines stochastic volatility with jump diffusion features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x46CcBQ0IrBd"
   },
   "source": [
    "**References**\n",
    "\n",
    "- Gatheral, Jim. *The Volatility Surface: A Practitioner's Guide*. John Wiley & Sons Inc., 2006.\n",
    "\n",
    "- Heston, Steven L. \"A Closed-Form Solution for Options with Stochastic Volatility with Applications to Bond and Currency Options.\" *The Review of Financial Studies*, vol. 6, no. 2, 1993, pp. 327-343.\n",
    "\n",
    "- Hilpisch, Yves. *Derivatives Analytics with Python: Data Analysis, Models,Simulation, Calibration and Hedging.* John Wiley & Sons, 2015."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "Copyright 2025 WorldQuant University. This\n",
    "content is licensed solely for personal use. Redistribution or\n",
    "publication of this material is strictly prohibited.\n"
   ]
  }
 ],
 "metadata": {
  "execution": {
   "timeout": 1000
  },
  "kernelspec": {
   "display_name": "msc_FE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
